# OpenAI Model Evaluation Configuration
# Optimized for GPT-4 and GPT-3.5 models

benchmark:
  name: "chimera-openai"
  version: "0.1.0"
  description: "CHIMERA benchmark configuration for OpenAI models"

model:
  provider: "openai"
  # Use environment variable for model name with default
  name: "${CHIMERA_MODEL_NAME:gpt-4o-mini}"
  
  # OpenAI-optimized parameters
  temperature: 0.0
  max_tokens: 2048
  top_p: 1.0
  
  # OpenAI timeouts and retries
  timeout_seconds: 120
  max_retries: 5
  retry_delay_seconds: 2.0

tracks:
  calibration:
    enabled: true
    max_samples: 500
    difficulty_levels: ["L1", "L2", "L3", "L4", "L5"]
    categories:
      - "factual"
      - "reasoning"
      - "numerical"
      - "commonsense"

  error_detection:
    enabled: true
    max_samples: 300
    include_self_review: true
    error_types:
      - "factual"
      - "logical"
      - "arithmetic"
      - "incomplete"
      - "hallucination"
      - "temporal"

  knowledge_boundary:
    enabled: true
    max_samples: 400
    question_types:
      - "answerable"
      - "unanswerable_impossible"
      - "unanswerable_specific"
      - "obscure_facts"
      - "fictional"

  self_correction:
    enabled: true
    max_samples: 250
    perturbation_types:
      - "value_corruption"
      - "step_removal"
      - "logic_inversion"
      - "premise_change"

evaluation:
  n_bins: 15
  bin_strategy: "uniform"
  bootstrap_samples: 1000
  confidence_level: 0.95
  abstention_confidence_threshold: 0.3
  error_detection_threshold: 0.5

prompts:
  elicit_confidence: true
  confidence_format: "numeric"
  include_reasoning: true
  system_additions: |
    You are a helpful AI assistant. When answering questions:
    1. Provide your answer clearly and concisely
    2. Express your confidence as a percentage (0-100%)
    3. Briefly explain your reasoning
    4. If you're uncertain, say so honestly

output:
  results_dir: "${CHIMERA_OUTPUT_DIR:results/openai}"
  experiment_name: null
  timestamp_format: "%Y%m%d_%H%M%S"
  save_raw_responses: true
  save_parsed_responses: true
  save_intermediate_results: true
  generate_html_report: true
  generate_markdown_report: true
  generate_plots: true

logging:
  level: "${CHIMERA_LOG_LEVEL:INFO}"
  format: "rich"
  log_file: null

cache:
  enabled: true
  cache_dir: ".api_cache/openai"
  ttl_hours: 24

rate_limiting:
  enabled: true
  # OpenAI has stricter rate limits
  requests_per_minute: 30
  tokens_per_minute: 60000
